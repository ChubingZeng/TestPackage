% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ipreg.R
\name{ipreg}
\alias{ipreg}
\title{Fit penalized regression with differential shrinkage based on external information.}
\usage{
ipreg(X, Y, Z = NULL, sigma.square = NULL, method = c("lasso", "ridge"),
  message = TRUE, control = list())
}
\arguments{
\item{X}{Numeric design matrix of explanatory variables (\eqn{n} observations in rows, \eqn{p} predictors in columns), without an intercept. \code{ipreg} includes an intercept by default.}

\item{Y}{Continuous outcome vector of dimension \eqn{n}.}

\item{Z}{Numeric information matrix about the predictors (\eqn{p} rows, each corresponding to a predictor in X; \eqn{q} columns of external information about the predictors, such as prior biological importance). If Z is the grouping of predictors, it is best if user codes it as a dummy variable (i.e. each column indicating whether predictors belong to a specific group)}

\item{sigma.square}{A user-supplied noise variance estimate. Typically, this is left unspecified, and the function automatically computes an estimated sigma square values using R package \code{selectiveinference}.}

\item{method}{The type of regularization applied in the model. method = 'lasso' for Lasso regression, method = 'ridge' for Ridge regression}

\item{message}{Generates diagnostic message in model fitting. Default is TRUE.}

\item{control}{Specifies \code{ipreg} control object. See \code{\link{ipreg.control}} for more details.}
}
\value{
An object with S3 class \code{ipreg} containing:
\item{beta.est}{The fitted vector of coefficients.}
\item{penalty.vector}{The estimated penalty vector applied to each regression coefficient. Similar to the \code{penalty.factor} argument in \link{glmnet}.}
\item{lambda}{The estimated \eqn{\lambda} value. Note that the lambda value is calculated to reflect that the fact that penalty factors are internally rescaled to sum to nvars in \link{glmnet}. Similar to the \code{lambda} argument in \link{glmnet}.}
\item{n_iter}{Number of iterations used until convergence.}
\item{method}{Same as in argument above}
\item{sigma.square}{The estimated sigma square value using \code{\link{estimateVariance}}, if \code{sigma.square} is left unspecified.}
\item{likelihood.score}{A vector containing the marginal likelihood value of the fitted model at each iteration.}
}
\description{
\code{ipreg} uses an Empirical Bayes approach to integrate external information into penalized linear regression models. It fits models with differential amount of shrinkages for each regression coefficient based on external information.
}
\details{
\code{ipreg} has two main usages:
\itemize{
\item The basic usage of it is to choose the tuning parameter \eqn{\lambda} in Lasso and Ridge regression using an
Empirical Bayes approach, as an alternative to the widely-used cross-validation. This is done by calling \code{ipreg} without specifying external information matrix Z.

\item More importantly, if an external information Z about the predictors X is provided, \code{ipreg} can allow differential shrinkage
parameters for regression coefficients in penalized regression models. The idea is that Z might be informative for the effect-size of regression coefficients, therefore we can guide the penalized regression model using Z.
}

Please note that the number of rows in Z should match with the number of columns in X. Since each column in Z is a feature about X. \href{https://github.com/ChubingZeng/ipreg}{See here for more details on how to specify Z}.

A majorization-minimization procedure is employed to fit \code{ipreg}.
}
\examples{
## use simulated example data
set.seed(9)
data(example)
X <- example$X
Y <- example$Y
Z <- example$Z

## Empirical Bayes tuning to estimate tuning parameter, as an alternative to cross-validation:
fit.eb <- ipreg(X,Y)
fit.eb$lambda

### compare with tuning parameter choosen by cross-validation, using glmnet
\dontrun{
fit.cv <- cv.glmnet(X,Y,alpha = 1)
fit.cv$lambda.min
}
## Differential shrinkage based on external information Z:
fit.diff <- ipreg(X,Y,Z)
fit.diff$penalty.vector

}
\seealso{
\link{predict.ipreg}, as well as \link{glmnet}.
}
\author{
Chubing Zeng
}
